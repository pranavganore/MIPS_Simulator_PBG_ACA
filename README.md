Author: Pranav Ganore
Objective : 
            To experience the design issues of advanced computer architectures through the design of an analyzer for a simplified MIPS CPU using high level programming languages. The considered MIPS CPU adopts a multi-cycle pipeline processor to dynamically schedule instruction execution and employs caches in order to expedite memory access.
Project Statement : 
                    Consider a simplified version of the MIPS instruction set architecture shown below in Table 1 and whose formats are provided at the end of this document.
                    Table 1: Reduced MIPS instruction set
Instruction Class
Instruction Mnemonic
Data Transfers
LW, SW, L.D, S.D
Arithmetic/ logical
DADD, DADDI, DSUB, DSUBI, AND, ANDI, OR, ORI,
ADD.D, MUL.D, DIV.D, SUB.D
Control
J, BEQ, BNE
Special purpose
HLT (to stop fetching new instructions)
You need to develop an architecture simulator for the MIPS computer whose organization is shown in Figure 1. The simulator is to accept a program as an input in the MIPS assembly using the subset of instructions in Table 1. The output of simulator will be a file containing the cycle time at which each instruction completes the various stages, and statistics for cache access. The detailed specifications of the input and output files will be provided later in this document. The following explains the CPU and Memory system:
Memory: The MIPS machine has an instruction cache (I-Cache) organized as direct-mapped with 4 blocks and the block size is 4 words. In addition, the machine has a data cache (D-Cache). D-Cache is a 2-way set associative with a total of four 4-words blocks. A least recently used block replacement strategy is to be applied for D-Cache. A write-back strategy is employed with a write-allocate policy. I-Cache is used in the instruction fetch stage while D-Cache is accessed in the memory stage. Both I-Cache and D-Cache are connected to main memory using a shared bus. In the case of a cache miss, if main memory is busy serving the other cache, we have to wait for it to be free and then start accessing it. In other words, latency of the main memory will be dynamic depending on the time of a request and the state of previous requests. If both caches experience a miss at the same cycle, the I-Cache will be given priority. The main memory is accessible through one-word-wide bus. The access time for memory,I-Cache (hit
Main MemoryRegister FileInstruction CacheData CacheInstruction decode (ID)Execute Stage (EX)Write Back (WB) Instruction Fetch (IF)Multi-stage Floating Point UnitInteger Unit (IU)Data Memory (MEM)
Figure 1: Block diagram description of a MIPS computer
Class Project CMSC611 – Advanced Computer Architecture, Fall 2019 2/8
time) and D-Cache (hit time) are specified as input in a configuration file, named “config.txt”. Memory is 2-way interleaved making the access time for 2 consecutive words equals T+k cycles, where T and k are the access time of memory and cache, respectively. All access to memory will be word-aligned. Thus, the cache miss penalty will be 2(T+k).
CPU: The MIPS computer employs a multi-stage pipeline processor in order to dynamically schedule instruction execution. There are generally four stages in the pipeline, namely, Instruction fetch (IF), instruction decoding and operand reading (ID), Execution (EX), and Write back (WB). The EX stage include both the ALU and data memory (MEM) access stages. There are four distinct ALU units for: one Integer arithmetic, one FP add/subtract, one FP multiplication, and one FP division. The integer unit (IU) always takes one cycle for the execution. The specification of whether the individual FP units are pipelined or not, as well as the latency of each unit are to be provided in an input file with the name “config.txt”. An example configuration is shown in Figure 2, where both the FP adder and multiplier are pipelined, tacking 4 and 6 cycles, respectively. The FP division is not pipelined and needs 20 cycles to complete. Note that the number of cycles for the instruction fetch (IF) and data access (MEM) stages depends on the cache performance, e.g. miss or hit. For load and store instructions, the address is calculated by IU before the data cache is accessed. Meanwhile for the integer instructions, e.g., DADD, the instruction will spend only 1 cycle MEM stage, before advancing WB stage.
The pipelined processor enables instruction-level parallelism with in-order issue, out-of-order execution and out-of-order completion. All instructions should pass through the IF stage in order. If an instruction cannot leave the ID stage because a functional unit is busy, a subsequent instruction will not be fetched. However, if instructions use different functional units after they pass the ID stage, they can get stalled or bypass each other in the EX stage and thus leave the EX stage out of order. Unconditional jumps complete in the ID stage. The fetched instruction (the next instruction in the program) will be flushed from IF stage in that case. In other words, a “J” instruction will waste one cycle if the following instruction in the program is in cache, or waste as many cycles as the cache miss penalty if the next instruction was not in cache. Conditional branches are also resolved in the “ID” stage as well. Meanwhile the CPU will go ahead and fetch the next instruction, in other words, always “not-taken prediction” will be used in the IF stage. If the branch turns to be “non-taken” the pipeline will not be stalled. However, if the branch is taken, the control unit will flush the fetched instruction and update the program counter. In other words, if the branch is “Taken”, one cycle will be wasted (unless a cache miss is encountered while the branch is being evaluated). The branching instructions do not stall because of structural hazard related to the integer unit. On the other hand, a conditional branching instruction may suffer RAW hazard, in which case the instruction will be stalled in the ID stage until the RAW hazard is resolved.
